{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = pd.read_csv('../speeches_millercenter_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Summary</th>\n",
       "      <th>President</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34th time speak oval office year soon time wan...</td>\n",
       "      <td>In this broadcast from the Oval Office, Presid...</td>\n",
       "      <td>Ronald Reagan</td>\n",
       "      <td>National Archives</td>\n",
       "      <td>January 11, 1989</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>3289</td>\n",
       "      <td>Republican</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Transcript  \\\n",
       "0  34th time speak oval office year soon time wan...   \n",
       "\n",
       "                                             Summary      President  \\\n",
       "0  In this broadcast from the Oval Office, Presid...  Ronald Reagan   \n",
       "\n",
       "              Source              Date  \\\n",
       "0  National Archives  January 11, 1989   \n",
       "\n",
       "                                                 URL  Word Count Affiliation  \\\n",
       "0  https://millercenter.org/the-presidency/presid...        3289  Republican   \n",
       "\n",
       "   Label  \n",
       "0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((312,), (79,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_corpus, test_corpus, train_label_nums, test_label_nums, train_label_names, test_label_names = train_test_split(text_data['Transcript'],\n",
    "                                         np.array(text_data['Label']),\n",
    "                                         np.array(text_data['Affiliation']),\n",
    "                                         test_size=0.2, random_state=42)\n",
    "train_corpus.shape, test_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((234,), (78,), (79,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation and train split\n",
    "train_final_corpus, validation_corpus, train_final_label_nums, validation_label_nums, train_final_label_names, validation_label_names = train_test_split(train_corpus,\n",
    "                                         train_label_nums,\n",
    "                                         train_label_names,\n",
    "                                         test_size=0.25, random_state=42)\n",
    "train_final_corpus.shape, validation_corpus.shape, test_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize training speeches\n",
    "t = tf.keras.preprocessing.text.Tokenizer(oov_token='<UNK>')\n",
    "# fit the tokenizer on the documents\n",
    "t.fit_on_texts(train_final_corpus)\n",
    "t.word_index['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('heterosexual', 14929) ('<PAD>', 0) 1\n"
     ]
    }
   ],
   "source": [
    "print(max([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), \n",
    "      min([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), \n",
    "      t.word_index['<UNK>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = t.texts_to_sequences(train_final_corpus)\n",
    "val_sequences = t.texts_to_sequences(validation_corpus)\n",
    "test_sequences = t.texts_to_sequences(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size=14930\n",
      "Number of Documents=234\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size={}\".format(len(t.word_index)))\n",
    "print(\"Number of Documents={}\".format(t.document_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the below do? Limit the vector length? And why do we need it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((234, 2000), (78, 2000), (79, 2000))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 2000\n",
    "# pad dataset to a maximum review length in words\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_val = tf.keras.preprocessing.sequence.pad_sequences(val_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(t.word_index)\n",
    "EMBED_SIZE = 300\n",
    "EPOCHS=100\n",
    "BATCH_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = t.word_index\n",
    "# Word vectors downloaded from https://fasttext.cc/docs/en/english-vectors.html\n",
    "FASTTEXT_INIT_EMBEDDINGS_FILE = '../wiki-news-300d-1M-subword.vec'\n",
    "\n",
    "\n",
    "def load_pretrained_embeddings(word_to_index, max_features, embedding_size, embedding_file_path):    \n",
    "    \n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    embeddings_index = dict(get_coefs(*row.split(\" \")) \n",
    "                                for row in open(embedding_file_path, encoding=\"utf8\", errors='ignore') \n",
    "                                    if len(row)>100)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    nb_words = min(max_features, len(word_to_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embedding_size))\n",
    "    \n",
    "    for word, idx in word_to_index.items():\n",
    "        if idx >= max_features: \n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[idx] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does exactly the below? It uses the embeddings to create the corpus vector representation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_capstone/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14930, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_embeddings = load_pretrained_embeddings(word_to_index=word2idx, \n",
    "                                           max_features=VOCAB_SIZE, \n",
    "                                           embedding_size=EMBED_SIZE, \n",
    "                                           embedding_file_path=FASTTEXT_INIT_EMBEDDINGS_FILE)\n",
    "ft_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 2000, 300)         4479000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 2000, 256)         384256    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 400, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 400, 128)          163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 80, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 80, 64)            41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 5,396,697\n",
      "Trainable params: 5,396,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Embedding(VOCAB_SIZE, EMBED_SIZE,\n",
    "                                    weights=[ft_embeddings],\n",
    "                                    trainable=True,\n",
    "                                    input_length=MAX_SEQUENCE_LENGTH))\n",
    "\n",
    "model.add(tf.keras.layers.Conv1D(filters=256, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model below with a validation set to stop the training when it starts to overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6790 - accuracy: 0.5983 - val_loss: 0.6748 - val_accuracy: 0.6410\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6792 - accuracy: 0.6410 - val_loss: 0.6583 - val_accuracy: 0.6410\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6559 - accuracy: 0.6410 - val_loss: 0.6704 - val_accuracy: 0.6410\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6459 - accuracy: 0.6453 - val_loss: 0.6592 - val_accuracy: 0.6410\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6246 - accuracy: 0.6410Restoring model weights from the end of the best epoch.\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6246 - accuracy: 0.6410 - val_loss: 0.6660 - val_accuracy: 0.6410\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a36c9f790>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                      patience=3,\n",
    "                                      restore_best_weights=True,\n",
    "                                      verbose=1)\n",
    "\n",
    "model.fit(X_train, train_label_nums, \n",
    "          validation_data=(X_val, validation_label_nums),\n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          shuffle=True,\n",
    "          callbacks=[es],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-e42da4db2cc2>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Accuracy: 50.63%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        39\n",
      "           1       0.51      1.00      0.67        40\n",
      "\n",
      "    accuracy                           0.51        79\n",
      "   macro avg       0.25      0.50      0.34        79\n",
      "weighted avg       0.26      0.51      0.34        79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_capstone/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1\n",
       "0  0  39\n",
       "1  0  40"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = model.predict_classes(X_test, batch_size=2048, verbose=0).ravel()\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_score(test_label_nums.astype(int), predictions)*100))\n",
    "print(classification_report(test_label_nums, predictions))\n",
    "pd.DataFrame(confusion_matrix(test_label_nums, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now training without the validation set. We might need to do this because\n",
    "# we might not have enough data to split it, we might need all the data we have for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('spellman', 16710) ('<PAD>', 0) 1\n"
     ]
    }
   ],
   "source": [
    "# Tokenize training speeches\n",
    "t = tf.keras.preprocessing.text.Tokenizer(oov_token='<UNK>')\n",
    "# fit the tokenizer on the documents\n",
    "t.fit_on_texts(train_corpus)\n",
    "t.word_index['<PAD>'] = 0\n",
    "\n",
    "print(max([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), \n",
    "      min([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), \n",
    "      t.word_index['<UNK>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size=16711\n",
      "Number of Documents=312\n"
     ]
    }
   ],
   "source": [
    "train_sequences = t.texts_to_sequences(train_corpus)\n",
    "# val_sequences = t.texts_to_sequences(validation_corpus)\n",
    "test_sequences = t.texts_to_sequences(test_corpus)\n",
    "\n",
    "print(\"Vocabulary size={}\".format(len(t.word_index)))\n",
    "print(\"Number of Documents={}\".format(t.document_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(t.word_index)\n",
    "EMBED_SIZE = 300\n",
    "EPOCHS=100\n",
    "BATCH_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16711, 300)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx = t.word_index\n",
    "ft_embeddings = load_pretrained_embeddings(word_to_index=word2idx, \n",
    "                                           max_features=VOCAB_SIZE, \n",
    "                                           embedding_size=EMBED_SIZE, \n",
    "                                           embedding_file_path=FASTTEXT_INIT_EMBEDDINGS_FILE)\n",
    "ft_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2000, 300)         5013300   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 2000, 256)         384256    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 400, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 400, 128)          163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 80, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 80, 64)            41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 5,930,997\n",
      "Trainable params: 5,930,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Embedding(VOCAB_SIZE, EMBED_SIZE,\n",
    "                                    weights=[ft_embeddings],\n",
    "                                    trainable=True,\n",
    "                                    input_length=MAX_SEQUENCE_LENGTH))\n",
    "\n",
    "model.add(tf.keras.layers.Conv1D(filters=256, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((312, 2000), (79, 2000))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 2000\n",
    "# pad dataset to a maximum review length in words\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "# X_val = tf.keras.preprocessing.sequence.pad_sequences(val_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6804 - accuracy: 0.6442WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6804 - accuracy: 0.6442\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6619 - accuracy: 0.6410WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6619 - accuracy: 0.6410\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6544 - accuracy: 0.6410WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6544 - accuracy: 0.6410\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6432 - accuracy: 0.6410WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6432 - accuracy: 0.6410\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6245 - accuracy: 0.6410WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6245 - accuracy: 0.6410\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.6410WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6071 - accuracy: 0.6410\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5730 - accuracy: 0.6410WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.5730 - accuracy: 0.6410\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5172 - accuracy: 0.6506WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.5172 - accuracy: 0.6506\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.8013WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.4335 - accuracy: 0.8013\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3237 - accuracy: 0.8846WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.3237 - accuracy: 0.8846\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2453 - accuracy: 0.9872WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.2453 - accuracy: 0.9872\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1899 - accuracy: 0.9359WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.1899 - accuracy: 0.9359\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0952 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9808WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0647 - accuracy: 0.9808\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9968WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0243 - accuracy: 0.9968\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.6017e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 7.6017e-04 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.1568e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 4.1568e-04 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.1889e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 3.1889e-04 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.4435e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.4435e-04 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 9.0221e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 9.0221e-05 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.4475e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 3.4475e-05 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.5962e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 7.5962e-05 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.3710e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 1s/step - loss: 2.3710e-05 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.5867e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.5867e-05 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.9554e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.9554e-05 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.8722e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.8722e-05 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.9549e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.9549e-05 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.4246e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 3.4246e-05 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.0060e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0060e-05 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.1737e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.1737e-05 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.7471e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.7471e-05 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.4799e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.4799e-05 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.4462e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.4462e-05 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.2895e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.2895e-05 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.3054e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.3054e-05 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3659e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.3659e-05 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.8650e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.8650e-05 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.9122e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.9122e-05 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 9.1581e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 9.1581e-06 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.5025e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.5025e-05 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.7194e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.7194e-05 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3869e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.3869e-05 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.2795e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.2795e-05 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.5048e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.5048e-05 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.2327e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.2327e-05 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.4262e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.4262e-05 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.0990e-05 - accuracy: 1.0000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 490s 163s/step - loss: 2.0990e-05 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3558e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.3558e-05 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 8.0950e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 8.0950e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.0845e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.0845e-05 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 9.4268e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 9.4268e-06 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 8.2291e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 8.2291e-06 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.7699e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.7699e-05 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 8.9552e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 8.9552e-06 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.1048e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.1048e-05 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.1941e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.1941e-05 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.1534e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.1534e-05 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.5950e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.5950e-05 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 6.0533e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 6.0533e-06 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 8.9504e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 8.9504e-06 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.7030e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 4.7030e-05 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 6.4878e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 6.4878e-06 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.4734e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.4734e-05 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 5.8028e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 5.8028e-06 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3696e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.3696e-05 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.5674e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.5674e-05 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.3807e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 7.3807e-06 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.6112e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 3.6112e-05 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.0772e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.0772e-05 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.0891e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.0891e-05 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.8315e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.8315e-05 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 8.0572e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 8.0572e-06 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.4516e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 7.4516e-06 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 5.1001e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 5.1001e-06 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.8509e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 7.8509e-06 - accuracy: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - ETA: 0s - loss: 3.9167e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 3.9167e-06 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 6.1506e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 6.1506e-06 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 9.7416e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 9.7416e-06 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 9.0405e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 9.0405e-06 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.4609e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 3.4609e-06 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.6772e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.6772e-05 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 6.2250e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 6.2250e-06 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.0536e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.0536e-05 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.7685e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 4.7685e-06 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 6.5320e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 6.5320e-06 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.6953e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 3.6953e-06 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 5.3008e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 5.3008e-06 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.6810e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.6810e-05 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.5604e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 4.5604e-06 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.6061e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 7.6061e-06 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.2020e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 4.2020e-06 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.8627e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 4.8627e-06 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 5.4132e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 5.4132e-06 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.5337e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 4.5337e-06 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.3160e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.3160e-05 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 5.7399e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3/3 [==============================] - 3s 1s/step - loss: 5.7399e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a36ca0790>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                      patience=3,\n",
    "                                      restore_best_weights=True,\n",
    "                                      verbose=1)\n",
    "\n",
    "model.fit(X_train, train_label_nums, \n",
    "#           validation_data=(X_val, validation_label_nums),\n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          shuffle=True,\n",
    "          callbacks=[es],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.95%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.54      0.69        39\n",
      "           1       0.68      0.97      0.80        40\n",
      "\n",
      "    accuracy                           0.76        79\n",
      "   macro avg       0.82      0.76      0.75        79\n",
      "weighted avg       0.82      0.76      0.75        79\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  21  18\n",
       "1   1  39"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = model.predict_classes(X_test, batch_size=2048, verbose=0).ravel()\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_score(test_label_nums.astype(int), predictions)*100))\n",
    "print(classification_report(test_label_nums, predictions))\n",
    "pd.DataFrame(confusion_matrix(test_label_nums, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The performance improves without the validation dataset, probably because we have more training data\n",
    "# to train the model on.\n",
    "# Although it does overfit, so it would be best to just get more data and train again with a validation dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
